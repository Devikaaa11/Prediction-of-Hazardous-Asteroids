# -*- coding: utf-8 -*-
"""Hazardous Asteroid Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UZp65xuU-lfyH3ncrT88vu5RFs5wYvAP
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("/content/drive/MyDrive/SQL/project DSA/dataset.csv")

data=df.copy()

df.shape

df.columns

df_num=df.select_dtypes(include=['int64','float64'])
df_cat=df.select_dtypes(include=['object'])
print(f"Numerical columns={df_num.columns}")
print(f"\nCategorical columns={df_cat.columns}")

df.info()

pd.set_option("display.max_columns",None)

df.head()

df.tail()

df.describe()

# Number of unique values for each column
nunique_values = df.nunique()
print("\nNumber of unique values for each column:")
print(nunique_values)

# Unique values for each column
unique_values = {col: df[col].unique() for col in df.columns}
print("Unique values for each column:\n")
for col, values in unique_values.items():
    print(f"{col}: {values}\n\n")

# Value counts for each column
value_counts = {col: df[col].value_counts() for col in df.columns}
print("\nValue counts for each column:")
for col, counts in value_counts.items():
    print(f"\n{col}:\n{counts}")

#missing values for each column
data.isnull().sum()

df['pha'].value_counts()

df['pha'].value_counts(normalize=True)

"""It' highly imbalanced."""

df[df['neo']=='Y']['pha'].value_counts(normalize=True)*100

"""All phas are neos , while only 9% of neos comprise phas"""

df[df['prefix']=='A']['pha'].value_counts(normalize=True)*100

df_pha_y = df[df['pha'] == 'Y']

#count 'pha'='Y' for each 'prefix' value, including NaN
prefix_pha_y_counts = df_pha_y.groupby(df_pha_y['prefix'].fillna('NaN')).size()
print("Number of 'pha' = 'Y' for each prefix value (including NaN):")
print(prefix_pha_y_counts)

"""All 'A' prefixes are pha_no.

Since only missing values in prefix column contribute to pha_yes. It's an irrelevant column
"""

# df_pha_y = df[df['pha'] == 'Y']

class_pha_y_counts = df_pha_y.groupby('class').size()
class_pha_y_counts = class_pha_y_counts.sort_values(ascending=False)

print("Number of 'pha' = 'Y' for each class:")
print(class_pha_y_counts)

"""> Only 4 major classes are there in column 'class' that determine whether an asteroid is pha or not.





"""

orbit_id_pha_y_counts = df_pha_y.groupby('orbit_id').size()
orbit_id_pha_y_counts = orbit_id_pha_y_counts.sort_values(ascending=False)

print("Number of 'pha' = 'Y' for each orbit_id:")
print(orbit_id_pha_y_counts)

"""# Data Cleaning"""

df.duplicated().sum()  #no duplicates

"""Columns such as ' id ' ,' spkid ' , ' full_name ' , 'pdes ' , ' name ' consist of unique ids and doesn't hold any significance in prediction .Hence it can be dropped


Columns such as 'prefix','equinox' contain a singular value and do not hold any significance in prediction.Hence can be dropped
"""

df2=df.drop(columns=['id','spkid','full_name','pdes','name','prefix','equinox'])

#Reducing number of rows that gives pha_N to minimise the huge imalance within column,that might effect performance of the model.

df2['pha'] = df2['pha'].astype(str)

yes_df = df2[df2['pha'] == 'Y']
no_df = df2[df2['pha'] == 'N']

no_df['missing_values'] = no_df.isnull().sum(axis=1)

no_df_sorted = no_df.sort_values(by='missing_values', ascending=False)

num_to_remove = min(920000, len(no_df_sorted))
print(f"\n\nNumber of rows to remove: {num_to_remove}")

rows_to_remove = no_df_sorted.head(num_to_remove)

no_df_remaining = no_df_sorted.drop(rows_to_remove.index)

no_df_remaining = no_df_remaining.drop(columns=['missing_values'])

result_df = pd.concat([yes_df, no_df_remaining])

result_df.reset_index(drop=True, inplace=True)

print(f"\n\nResulting DataFrame Shape: {result_df.shape}")

# result_df.shape

result_df['pha'].value_counts(normalize=True)*100

result_df.info()

result_df.isna().sum()

"""Now, diameter ,albedo and diameter_sigma contain missing values"""

result_df.isna().sum()/result_df.shape[0]*100

result_df.columns

result_df_num=result_df.select_dtypes(include=['int64','float64'])
result_df_cat=result_df.select_dtypes(include=['object'])
print(f"Numerical columns={result_df_num.columns}")
print(f"\nCategorical columns={result_df_cat.columns}")

"""# EDA"""

df_test=result_df.copy()
df_test.head()

"""**Box-Plot**"""

numerical_columns = df_test.select_dtypes(include=['int64', 'float64']).columns

plt.figure(figsize=(15, len(numerical_columns) * 4))

for i, column in enumerate(numerical_columns, 1):
    plt.subplot(len(numerical_columns), 1, i)
    sns.boxplot(y=df[column], color='skyblue')
    plt.title(f'Box Plot of {column}')
    plt.xlabel('')
    plt.ylabel(column)

plt.tight_layout()
plt.show()

numerical_columns = result_df.select_dtypes(include=['int64', 'float64']).columns
num_vars = len(numerical_columns)

fig, axes = plt.subplots(nrows=num_vars, ncols=1, figsize=(12, 5 * num_vars))

for i, var in enumerate(numerical_columns):
    sns.boxplot(x='pha', y=result_df[var], data=result_df, ax=axes[i])
    axes[i].set_xlabel('PHA')
    axes[i].set_ylabel(var)
    axes[i].set_title(f'Box Plot of {var} by PHA')

plt.tight_layout()
plt.show()

"""**Correlation Matrix**"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df_test['pha'] = le.fit_transform(df_test['pha'])

numerical_df = df_test.select_dtypes(include='number')

corr_matrix = numerical_df.corr()

plt.figure(figsize=(25, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix')
plt.show()

#to find highly correlated columns with pha
if 'pha' in numerical_df.columns:
    pha_correlation = numerical_df.corr()['pha'].sort_values(ascending=False)

    threshold = 0.3
    highly_correlated = pha_correlation[abs(pha_correlation) > threshold]

    print("\nHighly Correlated Columns with 'pha':\n")
    print(highly_correlated)
else:
    print("The 'pha' column is not in the dataset.")

highly_correlated_sorted = highly_correlated.sort_values(ascending=True)

paired_palette = sns.color_palette('Paired')
color = paired_palette[0]

plt.figure(figsize=(4, 4))
sns.barplot(x=highly_correlated_sorted.values, y=highly_correlated_sorted.index, color=color)
plt.title('Correlation with PHA')
plt.xlabel('Correlation Coefficient')
plt.ylabel('Features')
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

highly_correlated_magnitude = highly_correlated.abs().sort_values(ascending=False)

plt.figure(figsize=(6,4))
sns.barplot(x=highly_correlated_magnitude.values, y=highly_correlated_magnitude.index, color=sns.color_palette('Blues', as_cmap=True)(0.6))
plt.title('Magnitude of Correlation with PHA')
plt.xlabel('Absolute Correlation Coefficient')
plt.ylabel('Features')
plt.grid()
plt.show()

"""H , e , q , moid , n , a , and rms are highly correlated with pha"""

target_corr = corr_matrix['pha'].drop('pha')

# Extract and print high correlations (absolute value above a threshold)
threshold = 0.8
high_corr_pairs = []

for i in range(len(corr_matrix.columns)):
    for j in range(i + 1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) > threshold:
            colname1 = corr_matrix.columns[i]
            colname2 = corr_matrix.columns[j]
            corr_value = corr_matrix.iloc[i, j]
            # Get correlations with the target column 'pha'
            corr_with_target_col1 = target_corr.get(colname1, 0)
            corr_with_target_col2 = target_corr.get(colname2, 0)
            high_corr_pairs.append((colname1, colname2, corr_value, corr_with_target_col1, corr_with_target_col2))

print(f"Highly correlated pairs (absolute correlation > {threshold}):")
for col1, col2, corr_value, corr_with_target_col1, corr_with_target_col2 in high_corr_pairs:
    print(f"{col1} and {col2}: Correlation = {corr_value:.2f}")
    print(f"  {col1} with 'pha': {corr_with_target_col1:.2f}")
    print(f"  {col2} with 'pha': {corr_with_target_col2:.2f}")

"""**Redundant feature elimination.**"""

result_df.drop(columns=['tp', 'per_y','moid_ld','epoch_mjd','epoch_cal'],inplace=True)
df_test.drop(columns=['tp', 'per_y','moid_ld','epoch_mjd','epoch_cal'],inplace=True)

result_df.drop(columns=['sigma_ad','sigma_per','sigma_om','sigma_tp','sigma_ma','sigma_e','sigma_i','sigma_q'],inplace=True)
df_test.drop(columns=['sigma_ad','sigma_per','sigma_om','sigma_tp','sigma_ma','sigma_e','sigma_i','sigma_q'],inplace=True)

result_df.info()

"""**Pair Plot**"""

sns.pairplot(result_df, hue='pha', vars=['H', 'moid', 'diameter','e','q','n'])
plt.show()

"""**Scatter plot**"""

df_test = df_test.dropna(subset=['diameter','diameter_sigma','albedo'])

fig, axes = plt.subplots(1, 3, figsize=(18, 6))

sns.scatterplot(x='H', y='diameter', data=df_test, ax=axes[0])
axes[0].set_title('H vs Diameter')
correlation = df_test['H'].corr(df_test['diameter'])

sns.scatterplot(x='H', y='diameter_sigma', data=df_test, ax=axes[1])
axes[1].set_title('H vs Diameter_sigma')

sns.scatterplot(x='H', y='albedo', data=df_test, ax=axes[2])
axes[2].set_title('H vs Albedo')

fig.suptitle('Scatter Plots of H with Diameter, Diameter_sigma, and Albedo', fontsize=16)

plt.tight_layout()
plt.show()
print(f"Correlation coefficient between H and Diameter: {correlation}")

"""> The scatter plot shows a clear inverse relationship between H (Absolute Magnitude) and Diameter. As H increases, the Diameter generally decreases, which aligns with the negative correlation coefficient of -0.666.

# Missing value imputation

Since the scatter plot of diameter and H suggests a linear trend (even if weak), missing value imputation using linear Regression can be effective.
"""

df_test.isnull().sum().sum()

"""**Imputation using Linear Regression**"""

from sklearn.linear_model import LinearRegression

# Fit the model using H to predict diameter
reg = LinearRegression()
reg.fit(df_test[['H']], df_test['diameter'])

# Predict missing diameter values based on H
missing_diameter = result_df[result_df['diameter'].isnull()]
predicted_diameter = reg.predict(missing_diameter[['H']])

result_df.loc[result_df['diameter'].isnull(), 'diameter'] = predicted_diameter

"""**Histplot**"""

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.histplot(df_test['diameter_sigma'], kde=True)
plt.title('Distribution of diameter_sigma')

plt.subplot(1, 2, 2)
sns.histplot(df_test['albedo'], kde=True)
plt.title('Distribution of albedo')

plt.show()

# Plot boxplots for diameter_sigma and albedo
plt.figure(figsize=(10, 6))

plt.subplot(1, 2, 1)
sns.boxplot(x=df_test['diameter_sigma'])
plt.title('Boxplot of diameter_sigma')

plt.subplot(1, 2, 2)
sns.boxplot(x=df_test['albedo'])
plt.title('Boxplot of albedo')

plt.show()

"""Distribution is skewd and has outliers.

**Fill with median**
"""

result_df['diameter_sigma'].fillna(result_df['diameter_sigma'].median(), inplace=True)

result_df['albedo'].fillna(result_df['albedo'].median(), inplace=True)

result_df.isnull().sum().sum()

"""**Simplifing the column class**"""

print(class_pha_y_counts)

retain_classes = ['APO', 'ATE', 'AMO', 'IEO']

result_df['class'] = result_df['class'].apply(lambda x: x if x in retain_classes else 'Other')

new_class_counts = result_df['class'].value_counts()
print(new_class_counts)

import matplotlib.pyplot as plt

colors = ['gold' if label != 'Other' else 'lightgreen' for label in new_class_counts.index]
plt.figure(figsize=(4,4))
plt.bar(new_class_counts.index, new_class_counts.values, color=colors)
plt.title('Class Distribution')
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()

"""**Dropping orbit_id**"""

droped_orbit_df=result_df.copy()

droped_orbit_df=result_df.drop(['orbit_id'],axis='columns')

droped_orbit_df.shape

num_droped_orbit_df=droped_orbit_df.select_dtypes(include=['int64','float64'])
cat_droped_orbit_df=droped_orbit_df.select_dtypes(include=['object'])
print(f"Numerical columns={num_droped_orbit_df.columns}")
print(f"\nCategorical columns={cat_droped_orbit_df.columns}")

"""# Encoding

**One-hot encoding**
"""

encoded_df = pd.get_dummies(cat_droped_orbit_df, columns=['class', 'neo'])
print(encoded_df.head())
boolean_columns = encoded_df.columns.drop('pha')
encoded_df[boolean_columns] = encoded_df[boolean_columns].astype(int)
print("\n\n",encoded_df.head())

"""**Label Encoding**"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
encoded_df['pha'] = le.fit_transform(encoded_df['pha'])
encoded_df = encoded_df.astype(int)
print(encoded_df.head())

"""Combine encoded_df with numerical features."""

combined_df = pd.concat([num_droped_orbit_df, encoded_df], axis=1)
combined_df.head()

combined_df.shape

combined_df.columns

combined_df.info()

"""**Splitting into target (y) and features (x)**"""

x = combined_df.drop('pha', axis=1)
y = combined_df['pha']
x.head()
y.head()

"""**Train_Test_Split**"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)

"""# Handling imbalance

**SMOTETomek**
"""

from imblearn.combine import SMOTETomek

smote_tomek = SMOTETomek(sampling_strategy='auto', random_state=42)
X_resampled, y_resampled = smote_tomek.fit_resample(x_train, y_train)

from collections import Counter

print('Original dataset shape:', Counter(y_train))
print('Resampled dataset shape:', Counter(y_resampled))

y_train_counts = Counter(y_train)
y_resampled_counts = Counter(y_resampled)

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,6))

axes[0].bar(y_train_counts.keys(), y_train_counts.values(), color='skyblue')
axes[0].set_title('Original Dataset Distribution')
axes[0].set_xlabel('Class')
axes[0].set_ylabel('Count')


axes[1].bar(y_resampled_counts.keys(), y_resampled_counts.values(), color='salmon')
axes[1].set_title('Resampled Dataset Distribution')
axes[1].set_xlabel('Class')
axes[1].set_ylabel('Count')
plt.tight_layout()
plt.show()

"""# Scaling

Min-Max Scaling
"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_resampled = scaler.fit_transform(X_resampled)
x_test = scaler.transform(x_test)

"""# Model Training And Evaluation

**Logistic Regression**
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score,precision_score,recall_score

model = LogisticRegression(C=0.001, penalty='l2', random_state=42)
model.fit(X_resampled, y_resampled)
y_pred_lr=model.predict(x_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_lr))
print("\nClassification Report:\n", classification_report(y_test, y_pred_lr))
print("\nF1 Score:", f1_score(y_test, y_pred_lr))
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Precision:", precision_score(y_test, y_pred_lr))
print("Recall:", recall_score(y_test, y_pred_lr))

"""**DecisionTree**"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score,precision_score,recall_score

model = DecisionTreeClassifier(max_depth=10, random_state=42)
model.fit(X_resampled, y_resampled)
y_pred_dt=model.predict(x_test)

print("Train Accuracy\n")
y_pred_train=model.predict(X_resampled)
print("Confusion Matrix:\n", confusion_matrix(y_resampled, y_pred_train))
print("\nClassification Report:\n", classification_report(y_resampled, y_pred_train))
print("Accuracy:", accuracy_score(y_resampled, y_pred_train))

print("\n\n\nTest Accuracy")
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))
print("\nF1 Score:", f1_score(y_test, y_pred_dt))
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print("Precision:", precision_score(y_test, y_pred_dt))
print("Recall:", recall_score(y_test, y_pred_dt))

"""**Random Forest**"""

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(max_depth=10, random_state=42, n_estimators=100)
rf_model.fit(X_resampled, y_resampled)
y_pred_rf = rf_model.predict(x_test)

print("Train Accuracy\n\n")
y_pred_train_rf=rf_model.predict(X_resampled)
print("Confusion Matrix:\n", confusion_matrix(y_resampled, y_pred_train_rf))
print("\nClassification Report:\n", classification_report(y_resampled, y_pred_train_rf))
print("Accuracy:", accuracy_score(y_resampled, y_pred_train_rf))
print("Precision:", precision_score(y_resampled, y_pred_train_rf))
print("Recall:", recall_score(y_resampled, y_pred_train_rf))

print("\n\nTest Accuracy\n\n")
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))
print("\nF1 Score:", f1_score(y_test, y_pred_rf))
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Precision:", precision_score(y_test, y_pred_rf))
print("Recall:", recall_score(y_test, y_pred_rf))

"""**XGboost**"""

from xgboost import XGBClassifier

xgb_model = XGBClassifier(max_depth=10, random_state=42, n_estimators=100, eval_metric='logloss')
xgb_model.fit(X_resampled, y_resampled)
y_pred_xgb = xgb_model.predict(x_test)

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb))
print("\nClassification Report:\n", classification_report(y_test, y_pred_xgb))
print("\nF1 Score:", f1_score(y_test, y_pred_xgb))
print("Accuracy:", accuracy_score(y_test, y_pred_xgb))
print("Precision:", precision_score(y_test, y_pred_xgb))
print("Recall:", recall_score(y_test, y_pred_xgb))

"""Checking accuracy for both train and test sets to ensure it's **not overfitted**.

**Cross Validation**
"""

from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(model, X_resampled, y_resampled, cv=2, scoring='f1')

print("Cross-validation F1 scores:", cv_scores)
print("Mean CV F1 score:", cv_scores.mean())